{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "try:\n",
    "    import ujson as json  \n",
    "except:\n",
    "    import json\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "from operator import itemgetter\n",
    "from xml.etree import cElementTree as etree\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from xml C:\\Users\\Acer\\Desktop\\data\\Posts.xml\n",
      "Filtered: C:\\Users\\Acer\\Desktop\\data\\filtered.tsv\n",
      "Meta: C:\\Users\\Acer\\Desktop\\data\\filtered-meta.json\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(\"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\", \"Posts.xml\")\n",
    "print(\"Reading from xml %s\" % filename)\n",
    "filename_filtered = os.path.join(\"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\", \"filtered.tsv\")\n",
    "print(\"Filtered: %s\" % filename_filtered)\n",
    "filename_filtered_meta = os.path.join(\"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\", \"filtered-meta.json\")\n",
    "print(\"Meta: %s\" % filename_filtered_meta)\n",
    "q_creation = {} # creation datetimes of questions\n",
    "q_accepted = {} # id of accepted answer\n",
    "# question -> [(answer Id, IsAccepted, TimeToAnswer, Score), ...]\n",
    "meta = defaultdict(list)\n",
    "# regegx to find code snippets\n",
    "code_match = re.compile('<pre>(.*?)</pre>', re.MULTILINE | re.DOTALL)\n",
    "link_match = re.compile(\n",
    "'<a href=\"http://.*?\".*?>(.*?)</a>', re.MULTILINE | re.DOTALL)\n",
    "img_match = re.compile('<img(.*?)/>', re.MULTILINE | re.DOTALL)\n",
    "tag_match = re.compile('<[^>]*>', re.MULTILINE | re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Acer\\\\Desktop\\\\data\\\\filtered.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4451e275e367>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# preserve memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_filtered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparsexml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Acer\\\\Desktop\\\\data\\\\filtered.tsv'"
     ]
    }
   ],
   "source": [
    "def filter_html(s):\n",
    "    num_code_lines = 0\n",
    "    link_count_in_code = 0\n",
    "    code_free_s = s\n",
    "\n",
    "    num_images = len(img_match.findall(s))\n",
    "\n",
    "    for match_str in code_match.findall(s):\n",
    "        num_code_lines += match_str.count('\\n')\n",
    "        code_free_s = code_match.sub(\"\", code_free_s)\n",
    "\n",
    "        link_count_in_code += len(link_match.findall(match_str))\n",
    "\n",
    "    links = link_match.findall(s)\n",
    "    link_count = len(links)\n",
    "\n",
    "    link_count -= link_count_in_code\n",
    "\n",
    "    link_free_s = re.sub(\n",
    "        \" +\", \" \", tag_match.sub('', code_free_s)).replace(\"\\n\", \"\")\n",
    "\n",
    "    for link in links:\n",
    "        if link.lower().startswith(\"http://\"):\n",
    "            link_free_s = link_free_s.replace(link, '')\n",
    "\n",
    "    num_text_tokens = link_free_s.count(\" \")\n",
    "\n",
    "    return link_free_s, num_text_tokens, num_code_lines, link_count, num_images\n",
    "\n",
    "years = defaultdict(int)\n",
    "num_questions = 0\n",
    "num_answers = 0\n",
    "\n",
    "if sys.version_info.major < 3:\n",
    "   \n",
    "    from itertools import imap as map\n",
    "\n",
    "\n",
    "def parsexml(filename):\n",
    "    global num_questions, num_answers\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    it = map(itemgetter(1),\n",
    "             iter(etree.iterparse(filename, events=('start',))))\n",
    "\n",
    "    root = next(it)  # get posts element\n",
    "\n",
    "    for elem in it:\n",
    "        if counter % 100000 == 0:\n",
    "            print(\"Processed %i <row/> elements\" % counter)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        if elem.tag == 'row':\n",
    "            creation_date = dateparser.parse(elem.get('CreationDate'))\n",
    "\n",
    "            Id = int(elem.get('Id'))\n",
    "            PostTypeId = int(elem.get('PostTypeId'))\n",
    "            Score = int(elem.get('Score'))\n",
    "\n",
    "            if PostTypeId == 1:\n",
    "                num_questions += 1\n",
    "                years[creation_date.year] += 1\n",
    "\n",
    "                ParentId = -1\n",
    "                TimeToAnswer = 0\n",
    "                q_creation[Id] = creation_date\n",
    "                accepted = elem.get('AcceptedAnswerId')\n",
    "                if accepted:\n",
    "                    q_accepted[Id] = int(accepted)\n",
    "                IsAccepted = 0\n",
    "\n",
    "            elif PostTypeId == 2:\n",
    "                num_answers += 1\n",
    "\n",
    "                ParentId = int(elem.get('ParentId'))\n",
    "                if not ParentId in q_creation:\n",
    "                    # question was too far in the past\n",
    "                    continue\n",
    "\n",
    "                TimeToAnswer = (creation_date - q_creation[ParentId]).seconds\n",
    "\n",
    "                if ParentId in q_accepted:\n",
    "                    IsAccepted = int(q_accepted[ParentId] == Id)\n",
    "                else:\n",
    "                    IsAccepted = 0\n",
    "\n",
    "                meta[ParentId].append((Id, IsAccepted, TimeToAnswer, Score))\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            Text, NumTextTokens, NumCodeLines, LinkCount, NumImages = filter_html(\n",
    "                elem.get('Body'))\n",
    "\n",
    "            values = (Id, ParentId,\n",
    "                      IsAccepted,\n",
    "                      TimeToAnswer, Score,\n",
    "                      Text.encode(\"utf-8\"),\n",
    "                      NumTextTokens, NumCodeLines, LinkCount, NumImages)\n",
    "\n",
    "            yield values\n",
    "\n",
    "            root.clear()  # preserve memory\n",
    "\n",
    "with open(filename_filtered, \"w\") as f:\n",
    "    for values in parsexml(filename):\n",
    "        line = \"\\t\".join(map(str, values))\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "with open(filename_filtered_meta, \"w\") as f:\n",
    "    json.dump(meta, f)\n",
    "\n",
    "print(\"years:\", years)\n",
    "print(\"#qestions: %i\" % num_questions)\n",
    "print(\"#answers: %i\" % num_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit([[1],[2],[3],[4],[5],[6]], [0,0,0,1,1,1])\n",
    "knn.predict(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enchant is not installed, which is not a problem since spell correction features\n",
      "will not be used in the chapter. If, however, you want to experiment with them\n",
      "(highly encouraged!), you can get the library from http://packages.python.org/pyenchant/.\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Acer\\\\Desktop\\\\data\\\\filtered-meta.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-87ac16768401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mchosen_meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"chosen-meta.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mfiltered_meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Acer\\\\Desktop\\\\data\\\\filtered-meta.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    import ujson as json  # UltraJSON if available\n",
    "except:\n",
    "    import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    import enchant\n",
    "    speller = enchant.Dict(\"en_US\")\n",
    "\n",
    "except:\n",
    "    print(\"\"\"\\\n",
    "Enchant is not installed, which is not a problem since spell correction features\n",
    "will not be used in the chapter. If, however, you want to experiment with them\n",
    "(highly encouraged!), you can get the library from http://packages.python.org/pyenchant/.\n",
    "\"\"\")\n",
    "\n",
    "    class EnchantMock:\n",
    "\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def check(self, word):\n",
    "            return True\n",
    "    speller = EnchantMock()\n",
    "\n",
    "filtered = os.path.join(\"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\", \"filtered.tsv\")\n",
    "filtered_meta = os.path.join(\"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\", \"filtered-meta.json\")\n",
    "chosen = os.path.join(\"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\", \"chosen.tsv\")\n",
    "chosen_meta = os.path.join(\"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\", \"chosen-meta.json\")\n",
    "\n",
    "filtered_meta = json.load(open(filtered_meta, \"r\"))\n",
    "\n",
    "\n",
    "def misspelled_fraction(p):\n",
    "    tokens = p.split()\n",
    "    if not tokens:\n",
    "        return 0.0\n",
    "    return 1 - float(sum(speller.check(t) for t in tokens)) / len(tokens)\n",
    "\n",
    "\n",
    "def data(filename, col=None):\n",
    "    for line in open(filename, \"r\"):\n",
    "        data = line.strip().split(\"\\t\")\n",
    "\n",
    "        # check format\n",
    "        Id, ParentId, IsAccepted, TimeToAnswer, Score, Text, NumTextTokens, NumCodeLines, LinkCount, NumImages = data\n",
    "\n",
    "        if col:\n",
    "            yield data[col]\n",
    "        else:\n",
    "            yield data\n",
    "\n",
    "posts_to_keep = set()\n",
    "found_questions = 0\n",
    "\n",
    "num_qestion_sample = 1000\n",
    "\n",
    "\n",
    "filter_method = \"negative_positive\"  \n",
    "\n",
    "MaxAnswersPerQuestions = 10 \n",
    "\n",
    "\n",
    "\n",
    "unaccepted_scores = {}\n",
    "\n",
    "has_q_accepted_a = {}\n",
    "num_q_with_accepted_a = 0\n",
    "num_q_without_accepted_a = 0\n",
    "\n",
    "for ParentId, posts in filtered_meta.items():\n",
    "    assert ParentId != -1\n",
    "\n",
    "    if len(posts) < 2:\n",
    "        continue\n",
    "\n",
    "    ParentId = int(ParentId)\n",
    "    AllIds = set([ParentId])\n",
    "    AcceptedId = None\n",
    "    UnacceptedId = None\n",
    "    UnacceptedIds = []\n",
    "    UnacceptedScore = sys.maxsize\n",
    "\n",
    "    NegativeScoreIds = []\n",
    "    PositiveScoreIds = []\n",
    "\n",
    "    if filter_method == \"half-half\":\n",
    "\n",
    "        has_accepted_a = False\n",
    "        for post in posts:\n",
    "            Id, IsAccepted, TimeToAnswer, Score = post\n",
    "\n",
    "            if IsAccepted:\n",
    "                has_accepted_a = True\n",
    "                break\n",
    "\n",
    "        has_q_accepted_a[ParentId] = has_accepted_a\n",
    "\n",
    "        if has_accepted_a:\n",
    "            if num_q_with_accepted_a < num_qestion_sample / 2:\n",
    "                num_q_with_accepted_a += 1\n",
    "                posts_to_keep.add(ParentId)\n",
    "        else:\n",
    "            if num_q_without_accepted_a < num_qestion_sample / 2:\n",
    "                num_q_without_accepted_a += 1\n",
    "                posts_to_keep.add(ParentId)\n",
    "\n",
    "        if num_q_without_accepted_a + num_q_with_accepted_a > num_qestion_sample:\n",
    "            assert -1 not in posts_to_keep\n",
    "            break\n",
    "\n",
    "    else:\n",
    "\n",
    "        for post in posts:\n",
    "            Id, IsAccepted, TimeToAnswer, Score = post\n",
    "\n",
    "            if filter_method == \"all\":\n",
    "                AllIds.add(int(Id))\n",
    "\n",
    "            elif filter_method == \"only_one_per_class\":\n",
    "                if IsAccepted:\n",
    "                    AcceptedId = Id\n",
    "                elif Score < UnacceptedScore:\n",
    "                    UnacceptedScore = Score\n",
    "                    UnacceptedId = Id\n",
    "\n",
    "            elif filter_method == \"sample_per_question\":\n",
    "                if IsAccepted:\n",
    "                    AcceptedId = Id\n",
    "                else:\n",
    "                    UnacceptedIds.append(Id)\n",
    "\n",
    "            elif filter_method == \"negative_positive\":\n",
    "                if Score < 0:\n",
    "                    NegativeScoreIds.append((Score, Id))\n",
    "                elif Score > 0:\n",
    "                    PositiveScoreIds.append((Score, Id))\n",
    "\n",
    "            else:\n",
    "                raise ValueError(filter_method)\n",
    "\n",
    "        added = False\n",
    "        if filter_method == \"all\":\n",
    "            posts_to_keep.update(AllIds)\n",
    "            added = True\n",
    "        elif filter_method == \"only_one_per_class\":\n",
    "            if AcceptedId is not None and UnacceptedId is not None:\n",
    "                posts_to_keep.add(ParentId)\n",
    "                posts_to_keep.add(AcceptedId)\n",
    "                posts_to_keep.add(UnacceptedId)\n",
    "                added = True\n",
    "\n",
    "        elif filter_method == \"sample_per_question\":\n",
    "            if AcceptedId is not None and UnacceptedIds is not None:\n",
    "                posts_to_keep.add(ParentId)\n",
    "                posts_to_keep.add(AcceptedId)\n",
    "                posts_to_keep.update(UnacceptedIds[:MaxAnswersPerQuestions])\n",
    "                added = True\n",
    "\n",
    "        elif filter_method == \"negative_positive\":\n",
    "            if PositiveScoreIds and NegativeScoreIds:\n",
    "                posts_to_keep.add(ParentId)\n",
    "\n",
    "                posScore, posId = sorted(PositiveScoreIds)[-1]\n",
    "                posts_to_keep.add(posId)\n",
    "\n",
    "                negScore, negId = sorted(NegativeScoreIds)[0]\n",
    "                posts_to_keep.add(negId)\n",
    "                print(\"%i: %i/%i %i/%i\" % (ParentId, posId,\n",
    "                      posScore, negId, negScore))\n",
    "                added = True\n",
    "\n",
    "        if added:\n",
    "            found_questions += 1\n",
    "\n",
    "    if num_qestion_sample and found_questions >= num_qestion_sample:\n",
    "        break\n",
    "\n",
    "total = 0\n",
    "kept = 0\n",
    "\n",
    "already_written = set()\n",
    "chosen_meta_dict = defaultdict(dict)\n",
    "\n",
    "with open(chosen, \"w\") as f:\n",
    "    for line in data(filtered):\n",
    "        strId, ParentId, IsAccepted, TimeToAnswer, Score, Text, NumTextTokens, NumCodeLines, LinkCount, NumImages = line\n",
    "        Text = Text.strip()\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        Id = int(strId)\n",
    "        if Id in posts_to_keep:\n",
    "            if Id in already_written:\n",
    "                print(Id, \"is already written\")\n",
    "                continue\n",
    "\n",
    "            if kept % 100 == 0:\n",
    "                print(kept)\n",
    "\n",
    "            # setting meta info\n",
    "            post = chosen_meta_dict[Id]\n",
    "            post['ParentId'] = int(ParentId)\n",
    "            post['IsAccepted'] = int(IsAccepted)\n",
    "            post['TimeToAnswer'] = int(TimeToAnswer)\n",
    "            post['Score'] = int(Score)\n",
    "            post['NumTextTokens'] = int(NumTextTokens)\n",
    "            post['NumCodeLines'] = int(NumCodeLines)\n",
    "            post['LinkCount'] = int(LinkCount)\n",
    "            post['MisSpelledFraction'] = misspelled_fraction(Text)\n",
    "            post['NumImages'] = int(NumImages)\n",
    "            post['idx'] = kept  # index into the file\n",
    "\n",
    "            if int(ParentId) == -1:\n",
    "                q = chosen_meta_dict[Id]\n",
    "\n",
    "                if not 'Answers' in q:\n",
    "                    q['Answers'] = []\n",
    "\n",
    "                if filter_method == \"half-half\":\n",
    "                    q['HasAcceptedAnswer'] = has_q_accepted_a[Id]\n",
    "\n",
    "            else:\n",
    "                q = chosen_meta_dict[int(ParentId)]\n",
    "\n",
    "                if int(IsAccepted) == 1:\n",
    "                    assert 'HasAcceptedAnswer' not in q\n",
    "                    q['HasAcceptedAnswer'] = True\n",
    "\n",
    "                if 'Answers' not in q:\n",
    "                    q['Answers'] = [Id]\n",
    "                else:\n",
    "                    q['Answers'].append(Id)\n",
    "\n",
    "            f.writelines(\"%s\\t%s\\n\" % (Id, Text))\n",
    "            kept += 1\n",
    "\n",
    "with open(chosen_meta, \"w\") as fm:\n",
    "    json.dump(chosen_meta_dict, fm)\n",
    "\n",
    "print(\"total=\", total)\n",
    "print(\"kept=\", kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from operator import itemgetter\n",
    "from collections import Mapping\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_extraction.text import strip_accents_ascii, strip_accents_unicode\n",
    "\n",
    "import nltk\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    import ujson as json  # UltraJSON if available\n",
    "except:\n",
    "    import json\n",
    "\n",
    "poscache_filename = \"poscache.json\"\n",
    "\n",
    "\n",
    "class PosCounter(Counter):\n",
    "\n",
    "    def __init__(self, iterable=(), normalize=True, poscache=None, **kwargs):\n",
    "        self.n_sents = 0\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.poscache = poscache\n",
    "\n",
    "        super(PosCounter, self).__init__(iterable, **kwargs)\n",
    "\n",
    "    def update(self, other):\n",
    "        \"\"\"Adds counts for elements in other\"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            self.n_sents += other.n_sents\n",
    "            for x, n in other.items():\n",
    "                self[x] += n\n",
    "        else:\n",
    "            for sent in other:\n",
    "                self.n_sents += 1\n",
    "\n",
    "                if self.poscache is not None:\n",
    "                    if sent in self.poscache:\n",
    "                        tags = self.poscache[sent]\n",
    "                    else:\n",
    "                        self.poscache[sent] = tags = nltk.pos_tag(\n",
    "                            nltk.word_tokenize(sent))\n",
    "                else:\n",
    "                    tags = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "\n",
    "                for x in tags:\n",
    "                    tok, tag = x\n",
    "                    self[tag] += 1\n",
    "\n",
    "            if self.normalize:\n",
    "                for x, n in self.items():\n",
    "                    self[x] /= float(self.n_sents)\n",
    "\n",
    "\n",
    "class PosTagFreqVectorizer(BaseEstimator):\n",
    "\n",
    "    \"\"\"\n",
    "    Convert a collection of raw documents to a matrix Pos tag frequencies\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input='content', charset='utf-8',\n",
    "                 charset_error='strict', strip_accents=None,\n",
    "                 vocabulary=None,\n",
    "                 normalize=True,\n",
    "                 dtype=float):\n",
    "\n",
    "        self.input = input\n",
    "        self.charset = charset\n",
    "        self.charset_error = charset_error\n",
    "        self.strip_accents = strip_accents\n",
    "        if vocabulary is not None:\n",
    "            self.fixed_vocabulary = True\n",
    "            if not isinstance(vocabulary, Mapping):\n",
    "                vocabulary = dict((t, i) for i, t in enumerate(vocabulary))\n",
    "            self.vocabulary_ = vocabulary\n",
    "        else:\n",
    "            self.fixed_vocabulary = False\n",
    "\n",
    "        try:\n",
    "            self.poscache = json.load(open(poscache_filename, \"r\"))\n",
    "        except IOError:\n",
    "            self.poscache = {}\n",
    "\n",
    "        self.normalize = normalize\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def write_poscache(self):\n",
    "        json.dump(self.poscache, open(poscache_filename, \"w\"))\n",
    "\n",
    "    def decode(self, doc):\n",
    "        \"\"\"Decode the input into a string of unicode symbols\n",
    "\n",
    "        The decoding strategy depends on the vectorizer parameters.\n",
    "        \"\"\"\n",
    "        if self.input == 'filename':\n",
    "            doc = open(doc, 'rb').read()\n",
    "\n",
    "        elif self.input == 'file':\n",
    "            doc = doc.read()\n",
    "\n",
    "        if isinstance(doc, bytes):\n",
    "            doc = doc.decode(self.charset, self.charset_error)\n",
    "        return doc\n",
    "\n",
    "    def build_preprocessor(self):\n",
    "      \n",
    "        noop = lambda x: x\n",
    "\n",
    "        # accent stripping\n",
    "        if not self.strip_accents:\n",
    "            strip_accents = noop\n",
    "        elif hasattr(self.strip_accents, '__call__'):\n",
    "            strip_accents = self.strip_accents\n",
    "        elif self.strip_accents == 'ascii':\n",
    "            strip_accents = strip_accents_ascii\n",
    "        elif self.strip_accents == 'unicode':\n",
    "            strip_accents = strip_accents_unicode\n",
    "        else:\n",
    "            raise ValueError('Invalid value for \"strip_accents\": %s' %\n",
    "                             self.strip_accents)\n",
    "\n",
    "        only_prose = lambda s: re.sub('<[^>]*>', '', s).replace(\"\\n\", \" \")\n",
    "\n",
    "        return lambda x: strip_accents(only_prose(x))\n",
    "\n",
    "    def build_tokenizer(self):\n",
    "        \"\"\"Return a function that split a string in sequence of tokens\"\"\"\n",
    "        return nltk.sent_tokenize\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        \"\"\"Return a callable that handles preprocessing and tokenization\"\"\"\n",
    "\n",
    "        preprocess = self.build_preprocessor()\n",
    "\n",
    "        tokenize = self.build_tokenizer()\n",
    "\n",
    "        return lambda doc: tokenize(preprocess(self.decode(doc)))\n",
    "\n",
    "    def _term_count_dicts_to_matrix(self, term_count_dicts):\n",
    "        i_indices = []\n",
    "        j_indices = []\n",
    "        values = []\n",
    "        vocabulary = self.vocabulary_\n",
    "\n",
    "        for i, term_count_dict in enumerate(term_count_dicts):\n",
    "            for term, count in term_count_dict.items():\n",
    "                j = vocabulary.get(term)\n",
    "                if j is not None:\n",
    "                    i_indices.append(i)\n",
    "                    j_indices.append(j)\n",
    "                    values.append(count)\n",
    "            # free memory as we go\n",
    "            term_count_dict.clear()\n",
    "\n",
    "        shape = (len(term_count_dicts), max(vocabulary.values()) + 1)\n",
    "        spmatrix = sp.csr_matrix((values, (i_indices, j_indices)),\n",
    "                                 shape=shape, dtype=self.dtype)\n",
    "        return spmatrix\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "    \n",
    "        self.fit_transform(raw_documents)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, raw_documents, y=None):\n",
    "   \n",
    "        if self.fixed_vocabulary:\n",
    "       \n",
    "            analyze = self.build_analyzer()\n",
    "            term_counts_per_doc = [PosCounter(analyze(doc), normalize=self.normalize, poscache=self.poscache)for doc in raw_documents]\n",
    "            return self._term_count_dicts_to_matrix(term_counts_per_doc)\n",
    "\n",
    "        self.vocabulary_ = {}\n",
    "        # result of document conversion to term count dicts\n",
    "        term_counts_per_doc = []\n",
    "        term_counts = Counter()\n",
    "\n",
    "        analyze = self.build_analyzer()\n",
    "\n",
    "        for doc in raw_documents:\n",
    "            term_count_current = PosCounter(\n",
    "                analyze(doc), normalize=self.normalize, poscache=self.poscache)\n",
    "            term_counts.update(term_count_current)\n",
    "\n",
    "            term_counts_per_doc.append(term_count_current)\n",
    "\n",
    "        self.write_poscache()\n",
    "\n",
    "        terms = set(term_counts)\n",
    "\n",
    "      \n",
    "        self.vocabulary_ = dict(((t, i) for i, t in enumerate(sorted(terms))))\n",
    "\n",
    "        return self._term_count_dicts_to_matrix(term_counts_per_doc)\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        \n",
    "        if not hasattr(self, 'vocabulary_') or len(self.vocabulary_) == 0:\n",
    "\n",
    "            analyze = self.build_analyzer()\n",
    "            term_counts_per_doc = [Counter(analyze(doc)) for doc in raw_documents]\n",
    "        return self._term_count_dicts_to_matrix(term_counts_per_doc)\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n",
    "        if not hasattr(self, 'vocabulary_') or len(self.vocabulary_) == 0:\n",
    "            raise ValueError(\"Vocabulary wasn't fitted or is empty!\")\n",
    "\n",
    "        return [t for t, i in sorted(iter(self.vocabulary_.items()),\n",
    "                                     key=itemgetter(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "[0.09437188] [1.80094112]\n",
      "P(x=-1)=0.05\tP(x=7)=0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Acer\\\\Desktop\\\\charts\\\\log_reg_example_data.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3822cf48594d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0.75'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m pyplot.savefig(\n\u001b[1;32m---> 35\u001b[1;33m     os.path.join(CHART_DIR, \"log_reg_example_data.png\"), bbox_inches=\"tight\")\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, frameon, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   2092\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2094\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2096\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2073\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2074\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2075\u001b[1;33m                     **kwargs)\n\u001b[0m\u001b[0;32m   2076\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2077\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                 \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             _png.write_png(renderer._renderer, fh,\n\u001b[0;32m    523\u001b[0m                             self.figure.dpi, metadata=metadata)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[1;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[1;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'seek'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Acer\\\\Desktop\\\\charts\\\\log_reg_example_data.png'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "from matplotlib import pyplot\n",
    "CHART_DIR = \"C:\\\\Users\\\\Acer\\\\Desktop\\\\charts\"\n",
    "np.random.seed(3)\n",
    "\n",
    "num_per_class = 40\n",
    "X = np.hstack((norm.rvs(2, size=num_per_class, scale=2),\n",
    "              norm.rvs(8, size=num_per_class, scale=3)))\n",
    "y = np.hstack((np.zeros(num_per_class),\n",
    "               np.ones(num_per_class)))\n",
    "\n",
    "\n",
    "def lr_model(clf, X):\n",
    "    return 1.0 / (1.0 + np.exp(-(clf.intercept_ + clf.coef_ * X)))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logclf = LogisticRegression()\n",
    "print(logclf)\n",
    "logclf.fit(X.reshape(num_per_class * 2, 1), y)\n",
    "print(np.exp(logclf.intercept_), np.exp(logclf.coef_.ravel()))\n",
    "print(\"P(x=-1)=%.2f\\tP(x=7)=%.2f\" %\n",
    "      (lr_model(logclf, -1), lr_model(logclf, 7)))\n",
    "X_test = np.arange(-5, 20, 0.1)\n",
    "pyplot.figure(figsize=(10, 4))\n",
    "pyplot.xlim((-5, 20))\n",
    "pyplot.scatter(X, y, c=y)\n",
    "pyplot.xlabel(\"feature value\")\n",
    "pyplot.ylabel(\"class\")\n",
    "pyplot.grid(True, linestyle='-', color='0.75')\n",
    "pyplot.savefig(\n",
    "    os.path.join(CHART_DIR, \"log_reg_example_data.png\"), bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def lin_model(clf, X):\n",
    "    return clf.intercept_ + clf.coef_ * X\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()\n",
    "print(clf)\n",
    "clf.fit(X.reshape(num_per_class * 2, 1), y)\n",
    "X_odds = np.arange(0, 1, 0.001)\n",
    "pyplot.figure(figsize=(10, 4))\n",
    "pyplot.subplot(1, 2, 1)\n",
    "pyplot.scatter(X, y, c=y)\n",
    "pyplot.plot(X_test, lin_model(clf, X_test))\n",
    "pyplot.xlabel(\"feature value\")\n",
    "pyplot.ylabel(\"class\")\n",
    "pyplot.title(\"linear fit on original data\")\n",
    "pyplot.grid(True, linestyle='-', color='0.75')\n",
    "\n",
    "X_ext = np.hstack((X, norm.rvs(20, size=100, scale=5)))\n",
    "y_ext = np.hstack((y, np.ones(100)))\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_ext.reshape(num_per_class * 2 + 100, 1), y_ext)\n",
    "pyplot.subplot(1, 2, 2)\n",
    "pyplot.scatter(X_ext, y_ext, c=y_ext)\n",
    "pyplot.plot(X_ext, lin_model(clf, X_ext))\n",
    "pyplot.xlabel(\"feature value\")\n",
    "pyplot.ylabel(\"class\")\n",
    "pyplot.title(\"linear fit on additional data\")\n",
    "pyplot.grid(True, linestyle='-', color='0.75')\n",
    "pyplot.savefig(\n",
    "    os.path.join(CHART_DIR, \"log_reg_log_linear_fit.png\"), bbox_inches=\"tight\")\n",
    "\n",
    "pyplot.figure(figsize=(10, 4))\n",
    "pyplot.xlim((-5, 20))\n",
    "pyplot.scatter(X, y, c=y)\n",
    "pyplot.plot(X_test, lr_model(logclf, X_test).ravel())\n",
    "pyplot.plot(X_test, np.ones(X_test.shape[0]) * 0.5, \"--\")\n",
    "pyplot.xlabel(\"feature value\")\n",
    "pyplot.ylabel(\"class\")\n",
    "pyplot.grid(True, linestyle='-', color='0.75')\n",
    "pyplot.savefig(\n",
    "    os.path.join(CHART_DIR, \"log_reg_example_fitted.png\"), bbox_inches=\"tight\")\n",
    "\n",
    "X = np.arange(0, 1, 0.001)\n",
    "pyplot.figure(figsize=(10, 4))\n",
    "pyplot.subplot(1, 2, 1)\n",
    "pyplot.xlim((0, 1))\n",
    "pyplot.ylim((0, 10))\n",
    "pyplot.plot(X, X / (1 - X))\n",
    "pyplot.xlabel(\"P\")\n",
    "pyplot.ylabel(\"odds = P / (1-P)\")\n",
    "pyplot.grid(True, linestyle='-', color='0.75')\n",
    "\n",
    "pyplot.subplot(1, 2, 2)\n",
    "pyplot.xlim((0, 1))\n",
    "pyplot.plot(X, np.log(X / (1 - X)))\n",
    "pyplot.xlabel(\"P\")\n",
    "pyplot.ylabel(\"log(odds) = log(P / (1-P))\")\n",
    "pyplot.grid(True, linestyle='-', color='0.75')\n",
    "pyplot.savefig(\n",
    "    os.path.join(CHART_DIR, \"log_reg_log_odds.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import ujson as json  # UltraJSON if available\n",
    "except:\n",
    "    import json\n",
    "\n",
    "from matplotlib import pylab\n",
    "import numpy as np\n",
    "\n",
    "CHART_DIR = \"C:\\\\Users\\\\DELL\\\\Desktop\\\\charts\"\n",
    "\n",
    "\n",
    "def fetch_data(filename, col=None, line_count=-1, only_questions=False):\n",
    "    count = 0\n",
    "\n",
    "    for line in open(filename, \"r\"):\n",
    "        count += 1\n",
    "        if line_count > 0 and count > line_count:\n",
    "            break\n",
    "\n",
    "        data = Id, ParentId, IsQuestion, IsAccepted, TimeToAnswer, Score, Text, NumTextTokens, NumCodeLines, LinkCount, MisSpelledFraction = line.split(\n",
    "            \"\\t\")\n",
    "\n",
    "        IsQuestion = int(IsQuestion)\n",
    "\n",
    "        if only_questions and not IsQuestion:\n",
    "            continue\n",
    "\n",
    "        if col:\n",
    "            if col < 6:\n",
    "                val = int(data[col])\n",
    "            else:\n",
    "                val = data[col]\n",
    "\n",
    "            yield val\n",
    "\n",
    "        else:\n",
    "            Id = int(Id)\n",
    "            assert Id >= 0, line\n",
    "\n",
    "            ParentId = int(ParentId)\n",
    "\n",
    "            IsAccepted = int(IsAccepted)\n",
    "\n",
    "            assert not IsQuestion == IsAccepted == 1, \"%i %i --- %s\" % (\n",
    "                IsQuestion, IsAccepted, line)\n",
    "            assert (ParentId == -1 and IsQuestion) or (\n",
    "                ParentId >= 0 and not IsQuestion), \"%i %i --- %s\" % (ParentId, IsQuestion, line)\n",
    "\n",
    "            TimeToAnswer = int(TimeToAnswer)\n",
    "            Score = int(Score)\n",
    "            NumTextTokens = int(NumTextTokens)\n",
    "            NumCodeLines = int(NumCodeLines)\n",
    "            LinkCount = int(LinkCount)\n",
    "            MisSpelledFraction = float(MisSpelledFraction)\n",
    "            yield Id, ParentId, IsQuestion, IsAccepted, TimeToAnswer, Score, Text, NumTextTokens, NumCodeLines, LinkCount, MisSpelledFraction\n",
    "\n",
    "\n",
    "def fetch_posts(filename, with_index=True, line_count=-1):\n",
    "    count = 0\n",
    "\n",
    "    for line in open(filename, \"r\"):\n",
    "        count += 1\n",
    "        if line_count > 0 and count > line_count:\n",
    "            break\n",
    "\n",
    "        Id, Text = line.split(\"\\t\")\n",
    "        Text = Text.strip()\n",
    "\n",
    "        if with_index:\n",
    "\n",
    "            yield int(Id), Text\n",
    "\n",
    "        else:\n",
    "\n",
    "            yield Text\n",
    "\n",
    "\n",
    "def load_meta(filename):\n",
    "    meta = json.load(open(filename, \"r\"))\n",
    "    keys = list(meta.keys())\n",
    "\n",
    "    # JSON only allows string keys, changing that to int\n",
    "    for key in keys:\n",
    "        meta[int(key)] = meta[key]\n",
    "        del meta[key]\n",
    "\n",
    "    # post Id to index in vectorized\n",
    "    id_to_idx = {}\n",
    "    # and back\n",
    "    idx_to_id = {}\n",
    "\n",
    "    for PostId, Info in meta.items():\n",
    "        id_to_idx[PostId] = idx = Info['idx']\n",
    "        idx_to_id[idx] = PostId\n",
    "\n",
    "    return meta, id_to_idx, idx_to_id\n",
    "\n",
    "\n",
    "def plot_roc(auc_score, name, fpr, tpr):\n",
    "    pylab.figure(num=None, figsize=(6, 5))\n",
    "    pylab.plot([0, 1], [0, 1], 'k--')\n",
    "    pylab.xlim([0.0, 1.0])\n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('False Positive Rate')\n",
    "    pylab.ylabel('True Positive Rate')\n",
    "    pylab.title('Receiver operating characteristic (AUC=%0.2f)\\n%s' % (\n",
    "        auc_score, name))\n",
    "    pylab.legend(loc=\"lower right\")\n",
    "    pylab.grid(True, linestyle='-', color='0.75')\n",
    "    pylab.fill_between(tpr, fpr, alpha=0.5)\n",
    "    pylab.plot(fpr, tpr, lw=1)\n",
    "    pylab.savefig(\n",
    "        os.path.join(CHART_DIR, \"roc_\" + name.replace(\" \", \"_\") + \".png\"))\n",
    "\n",
    "\n",
    "def plot_pr(auc_score, name, precision, recall, label=None):\n",
    "    pylab.figure(num=None, figsize=(6, 5))\n",
    "    pylab.xlim([0.0, 1.0])\n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('Recall')\n",
    "    pylab.ylabel('Precision')\n",
    "    pylab.title('P/R (AUC=%0.2f) / %s' % (auc_score, label))\n",
    "    pylab.fill_between(recall, precision, alpha=0.5)\n",
    "    pylab.grid(True, linestyle='-', color='0.75')\n",
    "    pylab.plot(recall, precision, lw=1)\n",
    "    filename = name.replace(\" \", \"_\")\n",
    "    pylab.savefig(os.path.join(CHART_DIR, \"pr_\" + filename + \".png\"))\n",
    "\n",
    "\n",
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    c_f = sorted(zip(clf.coef_[0], vectorizer.get_feature_names()))\n",
    "    top = list(zip(c_f[:n], c_f[:-(n + 1):-1]))\n",
    "    for (c1, f1), (c2, f2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (c1, f1, c2, f2))\n",
    "\n",
    "\n",
    "def plot_feat_importance(feature_names, clf, name):\n",
    "    pylab.figure(num=None, figsize=(6, 5))\n",
    "    coef_ = clf.coef_\n",
    "    important = np.argsort(np.absolute(coef_.ravel()))\n",
    "    f_imp = feature_names[important]\n",
    "    coef = coef_.ravel()[important]\n",
    "    inds = np.argsort(coef)\n",
    "    f_imp = f_imp[inds]\n",
    "    coef = coef[inds]\n",
    "    xpos = np.array(list(range(len(coef))))\n",
    "    pylab.bar(xpos, coef, width=1)\n",
    "\n",
    "    pylab.title('Feature importance for %s' % (name))\n",
    "    ax = pylab.gca()\n",
    "    ax.set_xticks(np.arange(len(coef)))\n",
    "    labels = ax.set_xticklabels(f_imp)\n",
    "    for label in labels:\n",
    "        label.set_rotation(90)\n",
    "    filename = name.replace(\" \", \"_\")\n",
    "    pylab.savefig(os.path.join(\n",
    "        CHART_DIR, \"feat_imp_%s.png\" % filename), bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def plot_feat_hist(data_name_list, filename=None):\n",
    "    if len(data_name_list) > 1:\n",
    "        assert filename is not None\n",
    "\n",
    "    pylab.figure(num=None, figsize=(8, 6))\n",
    "    num_rows = int(1 + (len(data_name_list) - 1) / 2)\n",
    "    num_cols = int(1 if len(data_name_list) == 1 else 2)\n",
    "    pylab.figure(figsize=(5 * num_cols, 4 * num_rows))\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            pylab.subplot(num_rows, num_cols, 1 + i * num_cols + j)\n",
    "            x, name = data_name_list[i * num_cols + j]\n",
    "            pylab.title(name)\n",
    "            pylab.xlabel('Value')\n",
    "            pylab.ylabel('Fraction')\n",
    "            # the histogram of the data\n",
    "            max_val = np.max(x)\n",
    "            if max_val <= 1.0:\n",
    "                bins = 50\n",
    "            elif max_val > 50:\n",
    "                bins = 50\n",
    "            else:\n",
    "                bins = max_val\n",
    "            n, bins, patches = pylab.hist( x, bins=bins, normed=1, alpha=0.75)\n",
    "\n",
    "            pylab.grid(True)\n",
    "\n",
    "    if not filename:\n",
    "        filename = \"feat_hist_%s.png\" % name.replace(\" \", \"_\")\n",
    "\n",
    "    pylab.savefig(os.path.join(CHART_DIR, filename), bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def plot_bias_variance(data_sizes, train_errors, test_errors, name, title):\n",
    "    pylab.figure(num=None, figsize=(6, 5))\n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('Data set size')\n",
    "    pylab.ylabel('Error')\n",
    "    pylab.title(\"Bias-Variance for '%s'\" % name)\n",
    "    pylab.plot(\n",
    "        data_sizes, test_errors, \"--\", data_sizes, train_errors, \"b-\", lw=1)\n",
    "    pylab.legend([\"test error\", \"train error\"], loc=\"upper right\")\n",
    "    pylab.grid(True, linestyle='-', color='0.75')\n",
    "    pylab.savefig(\n",
    "        os.path.join(CHART_DIR, \"bv_\" + name.replace(\" \", \"_\") + \".png\"), bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def plot_k_complexity(ks, train_errors, test_errors):\n",
    "    pylab.figure(num=None, figsize=(6, 5))\n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('k')\n",
    "    pylab.ylabel('Error')\n",
    "    pylab.title('Errors for for different values of $k$')\n",
    "    pylab.plot(\n",
    "        ks, test_errors, \"--\", ks, train_errors, \"-\", lw=1)\n",
    "    pylab.legend([\"test error\", \"train error\"], loc=\"upper right\")\n",
    "    pylab.grid(True, linestyle='-', color='0.75')\n",
    "    pylab.savefig(\n",
    "        os.path.join(CHART_DIR, \"kcomplexity.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`bins` must be an integer, a string, or an array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[1;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mn_equal_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c68a2970f9c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m      \u001b[0mplot_feat_hist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqa_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m#plot_feat_hist([(qa_X[:, idx], feature_names[idx]) for idx in [1,0]], 'feat_hist_two.png')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-806744172664>\u001b[0m in \u001b[0;36mplot_feat_hist\u001b[1;34m(data_name_list, filename)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                 \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpylab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mpylab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3130\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3131\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3132\u001b[1;33m                       stacked=stacked, normed=normed, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   3133\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3134\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   6528\u001b[0m             \u001b[1;31m# this will automatically overwrite bins,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6529\u001b[0m             \u001b[1;31m# so that each histogram uses the same bins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6530\u001b[1;33m             \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6531\u001b[0m             \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# causes problems later if it's an int\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmlast\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[1;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             raise TypeError(\n\u001b[1;32m--> 719\u001b[1;33m                 '`bins` must be an integer, a string, or an array')\n\u001b[0m\u001b[0;32m    720\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_equal_bins\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`bins` must be positive, when an integer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: `bins` must be an integer, a string, or an array"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import neighbors\n",
    "\n",
    "DATA_DIR = \"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\"\n",
    "chosen = os.path.join(DATA_DIR, \"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\\\\chosen.tsv\")\n",
    "chosen_meta = os.path.join(DATA_DIR, \"C:\\\\Users\\\\Acer\\\\Desktop\\\\data\\\\chosen-meta.json\")\n",
    "\n",
    "# question Id -> {'features'->feature vector, 'answers'->[answer Ids]}, 'scores'->[scores]}\n",
    "# scores will be added on-the-fly as the are not in meta\n",
    "meta, id_to_idx, idx_to_id = load_meta(chosen_meta)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# The sorting below is only to ensure reproducable numbers. Further down\n",
    "# we will occasionally skip a fold when it contains instances of only\n",
    "# one label. The two lines below ensure that the behavior is exactly the\n",
    "# same for different runs.\n",
    "all_questions = sorted([q for q, v in meta.items() if v['ParentId'] == -1])\n",
    "all_answers = sorted([q for q, v in meta.items() if v['ParentId'] != -1])\n",
    "\n",
    "feature_names = np.array((\n",
    "    'NumTextTokens',\n",
    "    'NumCodeLines',\n",
    "    'LinkCount',\n",
    "    'AvgSentLen',\n",
    "    'AvgWordLen',\n",
    "    'NumAllCaps',\n",
    "    'NumExclams',\n",
    "    'NumImages'\n",
    "))\n",
    "\n",
    "\n",
    "def prepare_sent_features():\n",
    "    for pid, text in fetch_posts(chosen, with_index=True):\n",
    "        if not text:\n",
    "            meta[pid]['AvgSentLen'] = meta[pid]['AvgWordLen'] = 0\n",
    "        else:\n",
    "            from platform import python_version\n",
    "            if python_version().startswith('2'):\n",
    "                text = text.decode('utf-8')\n",
    "            sent_lens = [len(nltk.word_tokenize(\n",
    "                sent)) for sent in nltk.sent_tokenize(text)]\n",
    "            meta[pid]['AvgSentLen'] = np.mean(sent_lens)\n",
    "            meta[pid]['AvgWordLen'] = np.mean(\n",
    "                [len(w) for w in nltk.word_tokenize(text)])\n",
    "\n",
    "        meta[pid]['NumAllCaps'] = np.sum(\n",
    "            [word.isupper() for word in nltk.word_tokenize(text)])\n",
    "\n",
    "        meta[pid]['NumExclams'] = text.count('!')\n",
    "\n",
    "\n",
    "prepare_sent_features()\n",
    "\n",
    "\n",
    "def get_features(aid):\n",
    "    return tuple(meta[aid][fn] for fn in feature_names)\n",
    "\n",
    "qa_X = np.asarray([get_features(aid) for aid in all_answers])\n",
    "\n",
    "classifying_answer = \"good\"\n",
    "#classifying_answer = \"poor\"\n",
    "\n",
    "if classifying_answer == \"good\":\n",
    "    # Score > 0 tests => positive class is good answer\n",
    "    qa_Y = np.asarray([meta[aid]['Score'] > 0 for aid in all_answers])\n",
    "elif classifying_answer == \"poor\":\n",
    "    # Score <= 0 tests => positive class is poor answer\n",
    "    qa_Y = np.asarray([meta[aid]['Score'] <= 0 for aid in all_answers])\n",
    "else:\n",
    "    raise Exception(\"classifying_answer='%s' is not supported\" %\n",
    "                    classifying_answer)\n",
    "\n",
    "for idx, feat in enumerate(feature_names):\n",
    "     plot_feat_hist([(qa_X[:, idx], feat)])\n",
    "\n",
    "#plot_feat_hist([(qa_X[:, idx], feature_names[idx]) for idx in [1,0]], 'feat_hist_two.png')\n",
    "#plot_feat_hist([(qa_X[:, idx], feature_names[idx]) for idx in [3,4,5,6]], 'feat_hist_four.png')\n",
    "\n",
    "avg_scores_summary = []\n",
    "\n",
    "\n",
    "def measure(clf_class, parameters, name, data_size=None, plot=False):\n",
    "    start_time_clf = time.time()\n",
    "    if data_size is None:\n",
    "        X = qa_X\n",
    "        Y = qa_Y\n",
    "    else:\n",
    "        X = qa_X[:data_size]\n",
    "        Y = qa_Y[:data_size]\n",
    "\n",
    "    cv = KFold(n=len(X), n_folds=10, indices=True)\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "    scores = []\n",
    "    roc_scores = []\n",
    "    fprs, tprs = [], []\n",
    "\n",
    "    pr_scores = []\n",
    "    precisions, recalls, thresholds = [], [], []\n",
    "\n",
    "    for fold_idx, (train, test) in enumerate(cv):\n",
    "        X_train, y_train = X[train], Y[train]\n",
    "        X_test, y_test = X[test], Y[test]\n",
    "\n",
    "        only_one_class_in_train = len(set(y_train)) == 1\n",
    "        only_one_class_in_test = len(set(y_test)) == 1\n",
    "        if only_one_class_in_train or only_one_class_in_test:\n",
    "            # this would pose problems later on\n",
    "            continue\n",
    "\n",
    "        clf = clf_class(**parameters)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "\n",
    "        train_errors.append(1 - train_score)\n",
    "        test_errors.append(1 - test_score)\n",
    "\n",
    "        scores.append(test_score)\n",
    "        proba = clf.predict_proba(X_test)\n",
    "\n",
    "        label_idx = 1\n",
    "        fpr, tpr, roc_thresholds = roc_curve(y_test, proba[:, label_idx])\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(\n",
    "            y_test, proba[:, label_idx])\n",
    "\n",
    "        roc_scores.append(auc(fpr, tpr))\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "\n",
    "        pr_scores.append(auc(recall, precision))\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        thresholds.append(pr_thresholds)\n",
    "\n",
    "      \n",
    "        threshold_for_detecting_good_answers = 0.59\n",
    "\n",
    "        print(\"Clone #%i\" % fold_idx)\n",
    "        print(classification_report(y_test, proba[:, label_idx] >\n",
    "              threshold_for_detecting_good_answers, target_names=['not accepted', 'accepted']))\n",
    "\n",
    "    \n",
    "    scores_to_sort = pr_scores  # roc_scores\n",
    "    medium = np.argsort(scores_to_sort)[len(scores_to_sort) / 2]\n",
    "    print(\"Medium clone is #%i\" % medium)\n",
    "\n",
    "    if plot:\n",
    "        #plot_roc(roc_scores[medium], name, fprs[medium], tprs[medium])\n",
    "        plot_pr(pr_scores[medium], name, precisions[medium],\n",
    "                recalls[medium], classifying_answer + \" answers\")\n",
    "\n",
    "        if hasattr(clf, 'coef_'):\n",
    "            plot_feat_importance(feature_names, clf, name)\n",
    "\n",
    "    summary = (name,\n",
    "               np.mean(scores), np.std(scores),\n",
    "               np.mean(roc_scores), np.std(roc_scores),\n",
    "               np.mean(pr_scores), np.std(pr_scores),\n",
    "               time.time() - start_time_clf)\n",
    "    print(summary)\n",
    "    avg_scores_summary.append(summary)\n",
    "    precisions = precisions[medium]\n",
    "    recalls = recalls[medium]\n",
    "    thresholds = np.hstack(([0], thresholds[medium]))\n",
    "    idx80 = precisions >= 0.8\n",
    "    print(\"P=%.2f R=%.2f thresh=%.2f\" % (precisions[idx80][0], recalls[\n",
    "          idx80][0], thresholds[idx80][0]))\n",
    "\n",
    "    return np.mean(train_errors), np.mean(test_errors)\n",
    "\n",
    "\n",
    "def bias_variance_analysis(clf_class, parameters, name):\n",
    "    #import ipdb;ipdb.set_trace()\n",
    "    data_sizes = np.arange(60, 2000, 4)\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "    for data_size in data_sizes:\n",
    "        train_error, test_error = measure(\n",
    "            clf_class, parameters, name, data_size=data_size)\n",
    "        train_errors.append(train_error)\n",
    "        test_errors.append(test_error)\n",
    "\n",
    "    plot_bias_variance(data_sizes, train_errors,\n",
    "                       test_errors, name, \"Bias-Variance for '%s'\" % name)\n",
    "\n",
    "\n",
    "def k_complexity_analysis(clf_class, parameters):\n",
    "    ks = np.hstack((np.arange(1, 20), np.arange(21, 100, 5)))\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "    for k in ks:\n",
    "        parameters['n_neighbors'] = k\n",
    "        train_error, test_error = measure(\n",
    "            clf_class, parameters, \"%dNN\" % k, data_size=2000)\n",
    "        train_errors.append(train_error)\n",
    "        test_errors.append(test_error)\n",
    "\n",
    "    plot_k_complexity(ks, train_errors, test_errors)\n",
    "\n",
    "for k in [5]:\n",
    "# for k in [5, 10, 40]:\n",
    "    #measure(neighbors.KNeighborsClassifier, {'n_neighbors': k}, \"%iNN\" % k)\n",
    "    bias_variance_analysis(neighbors.KNeighborsClassifier, {\n",
    "                           'n_neighbors': k}, \"%iNN\" % k)\n",
    "    k_complexity_analysis(neighbors.KNeighborsClassifier, {'n_neighbors': k})\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for C in [0.1]:\n",
    "# for C in [0.01, 0.1, 1.0, 10.0]:\n",
    "    name = \"LogReg C=%.2f\" % C\n",
    "    bias_variance_analysis(LogisticRegression, {'penalty': 'l2', 'C': C}, name)\n",
    "    measure(LogisticRegression, {'penalty': 'l2', 'C': C}, name, plot=True)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "from operator import itemgetter\n",
    "for s in reversed(sorted(avg_scores_summary, key=itemgetter(1))):\n",
    "    print(\"%-20s\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\" % s)\n",
    "\n",
    "print(\"time spent:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
